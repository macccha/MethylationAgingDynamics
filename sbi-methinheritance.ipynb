{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation-Based Inference for Methylation Inheritance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm\n",
    "# from sbi import analysis as analysis\n",
    "import torch\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.inference import NPE\n",
    "# from sbi.inference import SNPE\n",
    "# from sbi.inference import simulate_for_sbi\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of prior and calculation of posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train inference of posterior distribution\n",
    "\n",
    "num_dim = 3\n",
    "#Create prior box\n",
    "priormin = [0.001,0.001,1]\n",
    "priormax = [0.999,3,1000]\n",
    "prior = BoxUniform(low=torch.as_tensor(priormin), high=torch.as_tensor(priormax))\n",
    "# Check prior, return PyTorch prior.\n",
    "prior, num_parameters, prior_returns_numpy = process_prior(prior)\n",
    "\n",
    "# Check simulator, returns PyTorch simulator able to simulate batches.\n",
    "simulatorn = process_simulator(simulator_s, prior, prior_returns_numpy)\n",
    "\n",
    "# Consistency check after making ready for sbi.\n",
    "check_sbi_inputs(simulatorn, prior)\n",
    "\n",
    "#Sample parameters from priors\n",
    "num_simulations = 10000\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = simulatorn(theta)\n",
    "print(\"theta.shape\", theta.shape)\n",
    "print(\"x.shape\", x.shape)\n",
    "\n",
    "#Inference step\n",
    "inference = NPE(prior=prior, density_estimator=\"nsf\")\n",
    "\n",
    "#Train\n",
    "density_estimator = inference.append_simulations(theta,x).train()\n",
    "\n",
    "#Create posterior\n",
    "posterior = inference.build_posterior(density_estimator)\n",
    "\n",
    "print(posterior) # prints how the posterior was trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save inferred posterior\n",
    "import pickle\n",
    "\n",
    "f = open('./nnsbi.pckl', 'wb')\n",
    "pickle.dump(posterior, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inferred posterior\n",
    "import pickle\n",
    "\n",
    "f = open('./nnsbi.pckl', 'rb')\n",
    "posterior = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files from CSV and fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load Amir Dataset\n",
    "\n",
    "readfile = pd.read_csv(\"/Users/ciarchi/Nextcloud/MethylationTransm/Julia/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create necessary containters for data\n",
    "\n",
    "data_vars = readfile[\"daughter.var\"]\n",
    "data_drift = readfile[\"meth.drift\"]\n",
    "meth_parent = readfile[\"methyPercent.parent\"]*0.01\n",
    "groups = readfile[\"group\"]\n",
    "skip = 7\n",
    "size = int(len(data_vars)/(skip)*7)\n",
    "sizet = len(data_vars)\n",
    "sim_vars = np.zeros(size)\n",
    "sim_drift = np.zeros(size)\n",
    "sim_noise = np.zeros(size)\n",
    "sim_parent = np.zeros(size)\n",
    "sim_group = np.zeros(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit alpha values to Amir data\n",
    "\n",
    "sel = 0\n",
    "percent = int(size/100) #Counter for progress\n",
    "print(\"One Percent: \" + str(percent) + \"\\n\") #Check percentage in datapoints\n",
    "act_percent = 0\n",
    "progress_bar = \"[\"+\" \"*99+\"]\"\n",
    "print(\"Progress: \" + \"\\n\" + progress_bar, end = \"\\r\")\n",
    "for i in range(0,sizet-skip,skip):\n",
    "    #print(i)\n",
    "    T = 10\n",
    "    dt = 0.01\n",
    "    Nt = int(T/dt)\n",
    "    m0 = meth_parent[i]\n",
    "    v0 = data_vars[i]\n",
    "    mf = m0+data_drift[i]\n",
    "    group = groups[i]\n",
    "    daughters = [0,0,0,0,0,0,0]\n",
    "    samplest = posterior.sample((1,), x=[mf,v0],show_progress_bars=False)\n",
    "    noise_s = float(torch.median(samplest[:,1]))\n",
    "    m01 = m0\n",
    "    if m01 < 0.5 and m01 > 0.25:\n",
    "        m01 -= 0.1\n",
    "    elif m01 > 0.5 and m01 < 0.75:\n",
    "        m01 += 0.1\n",
    "    #print(\"Starting values: \",noise_s, \" \", m01, \" \", m02)\n",
    "    for p in range(0,7):\n",
    "        ms1 = m01\n",
    "        # ms2 = m02\n",
    "        ms1 = trajectory(Nt,dt,ms1,noise_s)\n",
    "        # ms2 = trajectory(Nt,dt,ms2,noise_s)\n",
    "        daughters[p] = ms1#0.5*(ms1+ms2)\n",
    "    vart = np.var(daughters)\n",
    "    driftt = np.mean(daughters)-m0\n",
    "    #print(\"Confront: \", vart, \" \", v0, \" \", mf, \" \", np.mean(daughters))\n",
    "    # if abs(vart-v0)>v0*0.1:\n",
    "    #     print(\"Not fit well\")\n",
    "    #print(vart, \" \", v0, \" \", noise_s, \"\\n\")\n",
    "    for p in range(0,7):\n",
    "        sim_vars[sel+p] = vart\n",
    "        sim_drift[sel+p] = driftt\n",
    "        sim_noise[sel+p] = noise_s\n",
    "        sim_parent[sel+p] = m0\n",
    "        sim_group[sel+p] = group\n",
    "    sel+=7\n",
    "    current_per = sel\n",
    "    # print(current_per)\n",
    "    if current_per >= (act_percent+1)*percent:\n",
    "        act_percent+=1\n",
    "        progress_bar_t = \"[\"+\"|\"*act_percent+\" \"*(99-act_percent)+\"]\"\n",
    "        print(progress_bar_t, end =\"\\r\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatosave = np.array([sim_vars, sim_drift, sim_parent, sim_noise, sim_group]).transpose()\n",
    "dataset = pd.DataFrame({'variances': datatosave[:, 0], 'methdrift': datatosave[:, 1],'methylationParent': datatosave[:, 2], 'bin_var': datatosave[:, 3], 'group': datatosave[:, 4]})\n",
    "dataset.to_csv('/Users/ciarchi/Desktop/Acadm/MPI/CorrMethyMaintenance/daughterfitsbi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of functions and structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def trajectory(Nt,dt,ms,p,cov):\n",
    "    m_ = ms\n",
    "    for i in range(0,Nt):\n",
    "        m_ = m_ + dt*-((2*m_-1)-np.tanh(p*(2*m_-1))) + np.sqrt(dt/cov)*np.sqrt(abs(1-(2*m_-1)*np.tanh(p*(2*m_-1))))*np.random.normal()\n",
    "        if m_ < 0:\n",
    "            m_ = -m_\n",
    "        elif m_ > 1:\n",
    "            m_ = 2-m_\n",
    "    return m_\n",
    "    \n",
    "    \n",
    "def simulator(params):\n",
    "    T = 10\n",
    "    dt = 0.01\n",
    "    Nt = int(T/dt)\n",
    "    daughters = [0,0,0,0,0,0,0]\n",
    "    m10 = params[0]\n",
    "    noiset = params[1]\n",
    "    m1 = m10\n",
    "    m20 = m10\n",
    "    m2 = m10\n",
    "    # if m10 < 0.5 and m10 > 0.25:\n",
    "    #     m10 -= 0.1\n",
    "    # elif m10 > 0.5 and m10 < 0.75:\n",
    "    #     m10 += 0.1\n",
    "    # if m20 < 0.5 and m20 > 0.25:\n",
    "    #     m20 -= 0.1\n",
    "    # elif m20 > 0.5 and m20 < 0.75:\n",
    "    #     m20 += 0.1\n",
    "    for p in range(7):\n",
    "        m1 = trajectory(Nt,dt,m10,noiset,32)\n",
    "        m2 = trajectory(Nt,dt,m20,noiset,32)\n",
    "        #print(m1, \" \", m2, \"\\n\")\n",
    "        daughters[p] = (m1+m2)/2\n",
    "    # print(daughters, \" \", noiset)\n",
    "    return torch.as_tensor([np.mean(daughters),np.var(daughters)])\n",
    "\n",
    "#Simulate five trajectories at fixed coverage\n",
    "def simulator_s(params):\n",
    "    T = 10\n",
    "    dt = 0.01\n",
    "    Nt = int(T/dt)\n",
    "    m10 = params[0]\n",
    "    noiset = params[1]\n",
    "    daughters = [0,0,0,0,0]\n",
    "    cov = params[2]\n",
    "    m1 = m10\n",
    "    m20 = m10\n",
    "    m2 = m10\n",
    "    for p in range(5):\n",
    "        m1 = trajectory(Nt,dt,m10,noiset,cov)\n",
    "        m2 = trajectory(Nt,dt,m20,noiset,cov)\n",
    "        daughters[p] = (m1+m2)/2\n",
    "    return torch.as_tensor([np.mean(daughters),np.var(daughters),cov])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks for distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = [0.97,0.0001,765]\n",
    "samples = posterior.sample((100,), x=x_obs)\n",
    "#simulator(np.asarray(samples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.var(samples[:,1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pairplot(samples,\n",
    "             limits=[[0, 1], [-2, 2], [0, 1000]],\n",
    "             figsize=(6, 6),\n",
    "             labels=[r\"$\\theta_1$\", r\"$\\theta_2$\", r\"$\\theta_3$\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate dynamics for different values of alpha and look at average dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "#Time points\n",
    "Nt = 5000\n",
    "#Time-step\n",
    "dt = 0.01\n",
    "#Number of cells\n",
    "Nc = 5000\n",
    "#Path where to save figure\n",
    "save_path = \"/Users/ciarchi/Nextcloud/MethylationTransm/Pictures/Simulations/\"\n",
    "name_file = save_path+\"alpha_sim_Nc\"+str(Nc)+\"_Nt\"+str(Nt)+\"_dt\"+str(dt).replace(\".\",\"p\")+\".pdf\"\n",
    "#Initial methylation values\n",
    "m_init = 0.9\n",
    "#Vector of alpha values\n",
    "alphas = [2,1.9,1.8,1.7,1.6,1.5,1.4]\n",
    "#Vector of cells\n",
    "cells = [[[0 for _ in range(Nc)] for _ in range(Nt)] for _ in range(len(alphas))]\n",
    "#Iterate over cells, every cell simulates two alleles for Nt timesteps\n",
    "for a in range(0,len(alphas)):\n",
    "    alpha = alphas[a]\n",
    "    print(\"Doing \",alpha,\"\\n\")\n",
    "    for c in range(0,Nc):\n",
    "        m1 = m_init\n",
    "        m2 = m_init\n",
    "        for t in range(0,Nt):\n",
    "            m1 = m1 + dt*-((2*m1-1)-np.tanh(alpha*(2*m1-1))) + np.sqrt(dt/32)*np.sqrt(abs(1-(2*m1-1)*np.tanh(alpha*(2*m1-1))))*np.random.normal()\n",
    "            m2 = m2 + dt*-((2*m2-1)-np.tanh(alpha*(2*m2-1))) + np.sqrt(dt/32)*np.sqrt(abs(1-(2*m2-1)*np.tanh(alpha*(2*m1-1))))*np.random.normal()\n",
    "            if m1 < 0:\n",
    "                m1 = -m1\n",
    "            elif m1 > 1:\n",
    "                m1 = 2-m1\n",
    "            if m2 < 0:\n",
    "                m2 = -m2\n",
    "            elif m1 > 1:\n",
    "                m2 = 2-m2\n",
    "            cells[a][t][c] = 0.5*(m1+m2)\n",
    "\n",
    "#Average over cells\n",
    "trajectories = [[0 for _ in range(Nt)] for _ in range(len(alphas))]\n",
    "for a in range(0,len(alphas)):\n",
    "    for t in range(0,Nt):\n",
    "        trajectories[a][t] = np.mean(cells[a][t][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path where to save figure\n",
    "save_path = \"/Users/ciarchi/Nextcloud/MethylationTransm/Pictures/Simulations/\"\n",
    "name_file = save_path+\"alpha_sim_Nc\"+str(Nc)+\"_Nt\"+str(Nt)+\"_dt\"+str(dt).replace(\".\",\"p\")+\"_short_\"+\"norm\"+\".pdf\"\n",
    "#Plot as function of alpha\n",
    "time_points = np.arange(2000.0*dt, Nt*dt, dt)\n",
    "alpha_values = alphas\n",
    "num_alphas = len(alpha_values)\n",
    "    \n",
    "if time_points is None:\n",
    "    time_points = np.arange(Nt)\n",
    "if alpha_values is None:\n",
    "    alpha_values = [f'Alpha {i}' for i in range(num_alphas)]\n",
    "\n",
    "colormap = cm.get_cmap(\"viridis_r\", num_alphas)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.33333333333, 2.5))\n",
    "for i in range(num_alphas):\n",
    "    ax.plot(time_points, trajectories[i][2000:]/trajectories[i][2000], label=alpha_values[i], color=colormap(i / (num_alphas - 1)),linewidth=0.7)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Average methylation\")\n",
    "# plt.title(\"Curves for Different Coordination Strenghts\")\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "if save_path:\n",
    "        plt.savefig(name_file, format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time points\n",
    "Nt = 50000\n",
    "#Time-step\n",
    "dt = 0.01\n",
    "#Number of cells\n",
    "Nc = 1000\n",
    "#Initial methylation values\n",
    "m_init = 0.9\n",
    "#Vector of alpha values\n",
    "alphas = [1.6]\n",
    "#Vector of cells\n",
    "cells = [[[0 for _ in range(Nc)] for _ in range(Nt)] for _ in range(len(alphas))]\n",
    "#Iterate over cells, every cell simulates two alleles for Nt timesteps\n",
    "for a in range(0,len(alphas)):\n",
    "    alpha = alphas[a]\n",
    "    print(\"Doing \",alpha,\"\\n\")\n",
    "    for c in range(0,Nc):\n",
    "        m1 = m_init\n",
    "        m2 = m_init\n",
    "        for t in range(0,Nt):\n",
    "            m1 = m1 + dt*-((2*m1-1)-np.tanh(alpha*(2*m1-1))) + np.sqrt(dt/32)*np.sqrt(abs(1-(2*m1-1)*np.tanh(alpha*(2*m1-1))))*np.random.normal()\n",
    "            m2 = m2 + dt*-((2*m2-1)-np.tanh(alpha*(2*m2-1))) + np.sqrt(dt/32)*np.sqrt(abs(1-(2*m2-1)*np.tanh(alpha*(2*m1-1))))*np.random.normal()\n",
    "            if m1 < 0:\n",
    "                m1 = -m1\n",
    "            elif m1 > 1:\n",
    "                m1 = 2-m1\n",
    "            if m2 < 0:\n",
    "                m2 = -m2\n",
    "            elif m1 > 1:\n",
    "                m2 = 2-m2\n",
    "            cells[a][t][c] = 0.5*(m1+m2)\n",
    "\n",
    "#Average over cells\n",
    "trajectories_n = [[0 for _ in range(Nt)] for _ in range(len(alphas))]\n",
    "for a in range(0,len(alphas)):\n",
    "    for t in range(0,Nt):\n",
    "        trajectories_n[a][t] = np.mean(cells[a][t][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot as function of alpha\n",
    "time_points = np.arange(1000.0*dt, Nt*dt, dt)\n",
    "alpha_values = alphas\n",
    "num_alphas = len(alpha_values)\n",
    "    \n",
    "if time_points is None:\n",
    "    time_points = np.arange(Nt)\n",
    "if alpha_values is None:\n",
    "    alpha_values = [f'Alpha {i}' for i in range(num_alphas)]\n",
    "\n",
    "colormap = cm.get_cmap(\"viridis_r\", num_alphas)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.33333333333, 2.5))\n",
    "for i in range(num_alphas):\n",
    "    ax.plot(time_points, trajectories_n[i][1000:]/trajectories_n[i][1000], label=alpha_values[i],linewidth=0.7)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Average methylation\")\n",
    "# plt.title(\"Curves for Different Coordination Strenghts\")\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read ageing data and infere alpha values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Petkovich files and put into data frame, then infer alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read file\n",
    "readfile = pd.read_csv(\"/Users/ciarchi/Desktop/TMPAgeing/petkovich.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove coverages above 1000\n",
    "readfile.drop(readfile[readfile['cov'] >= 1000].index, inplace = True)\n",
    "readfile.drop(readfile[readfile['Age'] == \"2.5 (at isolation)\"].index, inplace = True)\n",
    "readfile.drop(readfile[pd.to_numeric(readfile['Age']) < 12.0].index, inplace = True)\n",
    "\n",
    "#Sample random row by start and tissue\n",
    "g = readfile.groupby(['chr', 'start'])\n",
    "\n",
    "readfile = readfile[g.ngroup().isin(np.random.choice(g.ngroups, 100000, replace=False))].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer alpha for every site\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "#Save vectors\n",
    "average_meth = readfile[\"avg.meth\"].tolist()\n",
    "average_cov = readfile[\"avg.cov\"].tolist()\n",
    "variance = readfile[\"var.meth\"].tolist()\n",
    "\n",
    "#Create vector of alphas\n",
    "alphas = np.zeros(len(average_meth))\n",
    "\n",
    "for i in tqdm(range(0,len(average_meth))):\n",
    "    if math.isnan(variance[i]):\n",
    "        alphas[i] = 2.0\n",
    "        continue\n",
    "    elif variance[i] == 0:\n",
    "        alphas[i] = 2.0\n",
    "        continue\n",
    "    else:\n",
    "        x_obs = [average_meth[i],variance[i],average_cov[i]]\n",
    "        alphas[i] = posterior.sample((1,), x=x_obs, show_progress_bars=False)[0,1].item()\n",
    "\n",
    "#Add column to data frame\n",
    "readfile[\"alpha\"] = alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Stubbs files and put into data frame, then infer alpha for every site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jn/hzpz5fjx36x_y2ydy2_b66sc0000gp/T/ipykernel_60785/4103929108.py:7: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  readfile = pd.read_csv(\"/Users/ciarchi/Desktop/TMPAgeing/Stubbs.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Read file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read file\n",
    "readfile = pd.read_csv(\"/Users/ciarchi/Desktop/TMPAgeing/Stubbs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Remove coverages above 1000\n",
    "readfile.drop(readfile[readfile['avg.cov'] >= 1000].index, inplace = True)\n",
    "\n",
    "#Sample random row by start and tissue\n",
    "g = readfile.groupby(['tissue', 'start'])\n",
    "\n",
    "readfile = readfile[g.ngroup().isin(np.random.choice(g.ngroups, 1000000, replace=False))].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d84bde510c485d8682c1d14b5c333b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Infer alpha for every site\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "#Save vectors\n",
    "average_meth = readfile[\"avg.meth\"].tolist()\n",
    "average_cov = readfile[\"avg.cov\"].tolist()\n",
    "variance = readfile[\"var.meth\"].tolist()\n",
    "\n",
    "#Create vector of alphas\n",
    "alphas = np.zeros(len(average_meth))\n",
    "\n",
    "for i in tqdm(range(0,len(average_meth))):\n",
    "    if math.isnan(variance[i]):\n",
    "        alphas[i] = 2.0\n",
    "        continue\n",
    "    elif variance[i] == 0:\n",
    "        alphas[i] = 2.0\n",
    "        continue\n",
    "    else:\n",
    "        x_obs = [average_meth[i],variance[i],average_cov[i]]\n",
    "        alphas[i] = posterior.sample((1,), x=x_obs, show_progress_bars=False)[0,1].item()\n",
    "\n",
    "#Add column to data frame\n",
    "readfile[\"alpha\"] = alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.tensor(readfile[['avg.meth','var.meth','avg.cov']].values).to(dtype=torch.float32) \n",
    "try_p = posterior.sample_batched((1,),x=obs,  max_sampling_batch_size = 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to .csv\n",
    "readfile.to_csv('/Users/ciarchi/Desktop/TMPAgeing/stubbs_alpha.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
